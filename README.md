# Triton Inference Server Examples
This repository provides the examples of serving model with Triton Inference Severer.

### Run jupyter notebook
```
$git clone https://github.com/GwangsooHong/triton_inference_server_examples
$cd triton_inference_server_examples
$jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --NotebookApp.token='' --allow-root
```

### Go to URL
```
http://{your server ip}:8888/ensemble_model_serving_example.ipynb
```
